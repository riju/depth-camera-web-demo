<!DOCTYPE html>
<html>
<head>
  <title>Depth Capture Based Hand Interaction Demo</title>
  <script src="../libs/ammo.js/ammo.js"></script>
  <script src="../libs/aframe/aframe-v0.8.0.js"></script>
  <script src="../libs/gl-matrix.js"></script>
  <script src="../libs/picogl.js/picogl.js"></script>
  <script src="../libs/picogl.js/utils.js"></script>
  <script src="../depth-camera.js"></script>
  <script src="depth_and_segments.js"></script>
</head>
<style>
html {
  overflow: hidden;
}
body {
  display: flex;
  flex-direction: column;
  font-family: 'Roboto', 'Noto', sans-serif;
  line-height: 1.5;
  background-color: #fbfbfb;
  margin: 0;
  text-align:center;
}
.info {
  position: absolute;
  top: 0px; width: 100%;
  padding: 5px;
  color: gray;
}
#timer {
  position: absolute;
  bottom: 10px;
  left: 10px;
  color: white;
}
#rotate-control {
  position: absolute;
  bottom: 20px;
  left: 20px;
  color: black;
  z-index: 5;
}
</style>
<body>
  <div id="rotate-control">
    Rotate - head mounted camera: <input id="rotate-toggle" type="checkbox" checked>
  </div>

  <script type="text/javascript">
    "use strict";
    let error = window.console.error;
    window.console.error = (message, ...rest) => {
      let target = document.querySelector('#console');
      error.call(window.console, message, ...rest);

      if (message instanceof Error) {
        message = `${message.name}: ${message.message}`;
      }

      target.innerHTML += `${message}<br>`;
    }

    utils.addTimerElement();

    const canvas = document.createElement("canvas");
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
    const gl = canvas.getContext("webgl2", {antialias: false});
    if (gl) {
      gl.color_buffer_float_ext = gl.getExtension('EXT_color_buffer_float');
      gl.WEBGL_get_buffer_sub_data_async =
          gl.getExtension("WEBGL_get_buffer_sub_data_async");
      gl.texture_float_linear = gl.getExtension("OES_texture_float_linear");
    }
    if (!gl || !gl.color_buffer_float_ext) {
      alert("The demo doesn't run because it requires WebGL2 support.");
      document.body.innerHTML = "The demo doesn't run because it requires WebGL2 support."
    }

    let scene;
    let camera;
    const DEBUG_DRAW_BONES = false;

    let physics;
    const viewscale = 15.0;
    let depthseg;
    const boxes = [];


    document.getElementById("rotate-toggle").addEventListener("change", function() {
      depthseg.setXZFlip(this.checked);
    });

    const depth_to_world_transform = mat4.create();
    const depth_mvp = mat4.create();
    const viewMatrix = mat4.create();
    const viewProjMatrix = mat4.create();
    const inverseViewProjMatrix = mat4.create();

    // UNIFORMS
/*    var projMatrix = mat4.create();
    var viewMatrix = mat4.create();
    var eyePosition = vec3.fromValues(0, 0.3, 0.4);
    mat4.lookAt(viewMatrix, eyePosition, vec3.fromValues(0, 0, 0), vec3.fromValues(0, 1, 0));

    var viewProjMatrix = mat4.create();
    let inverseViewProjMatrix = mat4.create();
    let depth_mvp = depthseg.getMVPMatrix();
    const depth_to_world_transform = mat4.create();
    const world_to_depth_transform = mat4.create();

    var lightPosition = vec3.fromValues(0.7, 0.5, 0.1); 
    var lightViewMatrix = mat4.create();
    var lightViewProjMatrix = mat4.create();
    const light_position_depth = vec3.create();
    mat4.lookAt(lightViewMatrix, lightPosition, vec3.fromValues(0, 0, 0), vec3.fromValues(0, 1, 0));
    updateMatrices();    

    function updateMatrices() {
      mat4.perspective(projMatrix, Math.PI / 2, window.innerWidth / window.innerHeight, 0.1, 10.0);
      mat4.multiply(viewProjMatrix, projMatrix, viewMatrix);
      mat4.multiply(lightViewProjMatrix, projMatrix, lightViewMatrix);
      mat4.invert(inverseViewProjMatrix, viewProjMatrix);
      depth_mvp = depthseg.getMVPMatrix();
      mat4.multiply(depth_to_world_transform, inverseViewProjMatrix, depth_mvp);
      mat4.invert(world_to_depth_transform, depth_to_world_transform);
      vec3.transformMat4(light_position_depth, lightPosition, world_to_depth_transform);
    }*/

    const SPOOL_OFFSET = 0;
    let spheres = [];
    var netspheres = [];
    let transform;

    // Temporary variables, preallocated.
    const temp = new glMatrix.ARRAY_TYPE(3);
    const temp1 = new glMatrix.ARRAY_TYPE(3);
    // keep track of sphere ids that are touching the scene objects.
    const contact_spheres = new Set();

    // btCollisionObjects.h constants.
    const ACTIVE_TAG = 1;
    const DISABLE_DEACTIVATION = 4;
    const WANTS_DEACTIVATION = 3;
    const CF_KINEMATIC_OBJECT = 2;
    const DISABLE_SIMULATION = 5;
    const CF_STATIC_OBJECT = 1;
    const CF_NO_CONTACT_RESPONSE = 4;
    const CF_CUSTOM_MATERIAL_CALLBACK = 8;
    const CF_CHARACTER_OBJECT = 16;
    let frameid = 1;
    let previous_frameid = 1;
    const SPHERES_OFFSET = 1000; // range of sphares used for bones offset.
    const NETSPHERES_OFFSET = 10000; // index mark the beginning of the offset
    // of an index of sphere used for large areas, e.g. arm, physics modeling.
    let updateFingerSegments;
    let updateMatrices;
    
    let camera3;
    let bt_zero_vec3;
    let bt_inertia;
    let btvec;
    let btquaternion;

    window.onresize = function() {
      if (camera3) // -> initialized
        updateMatrices();
    };

    function sceneLoaded() {
      depthseg = new DepthAndSegments(gl, scene.renderer.context);

      bt_zero_vec3 = new Ammo.btVector3(0, 0, 0);
      bt_inertia = new Ammo.btVector3(0, 0, 0);
      btvec = new Ammo.btVector3(0, 0, 0);
      btquaternion = new Ammo.btQuaternion(0, 0, 0, 0);

      transform = transform || new Ammo.btTransform();
      const children = scene.children;
      for (let i = 0; i < children.length; i++) {
        const child = children[i];
        if (child.tagName == "A-BOX") {
          boxes.push(child);
        }
      }

      function addNewSphere(spheres) {
        const sphere = {
          translate: [0, 0, 0],
          quat: [0, 0, 0, 1],
          scale: [0.01 * viewscale, 0.01 * viewscale, 0.01 * viewscale],
          mvpMatrix: mat4.create(),
          modelMatrix: mat4.create(),
          lightMvpMatrix: mat4.create(),
          mass: 0,
          visible: false,
          frameid: 0
        };
        spheres.push(sphere);
        return sphere;
      };

      for (let i = 0; i < 50; i++) {
        addNewSphere(spheres);
      }


      function createRigidBodySphere(sp, index) {
        let shape = new Ammo.btSphereShape(sp.scale[0]);
        transform.setIdentity();
        btvec.setValue(sp.translate[0], sp.translate[1], sp.translate[2]);
        btquaternion.setValue(sp.quat[0], sp.quat[1], sp.quat[2], sp.quat[3]);
        transform.setOrigin(btvec);
        transform.setRotation(btquaternion);
        let motionState = new Ammo.btDefaultMotionState(transform);

        bt_inertia.setValue(0, 0, 0);
        shape.calculateLocalInertia(sp.mass, bt_inertia);

        let info = new Ammo.btRigidBodyConstructionInfo(sp.mass, motionState, shape, bt_inertia);
        info.m_friction = 10.0; // high friction for hands.
        let body = new Ammo.btRigidBody(info);
        sp.physics_body = body;
        body.setUserPointer(sp);
        body.setUserIndex(index);
        if (!sp.visible)
          body.forceActivationState(DISABLE_SIMULATION);
        sp.constraints = [];
        if (sp.mass > 0) {
          body.setActivationState(DISABLE_DEACTIVATION);
        } else if (sp.hasOwnProperty("frameid")) {
          body.setCollisionFlags(CF_NO_CONTACT_RESPONSE | CF_STATIC_OBJECT);
        }
        physics.addRigidBody(body);
      }

      const tip = new glMatrix.ARRAY_TYPE(3);
      const base = new glMatrix.ARRAY_TYPE(3);
      const subtract = new glMatrix.ARRAY_TYPE(3);
      const quaternion = new glMatrix.ARRAY_TYPE(4);
      const draw_transform = mat4.create();
      const yUnitVec3 = vec3.fromValues(0,1,0);
      const far_away = new Ammo.btTransform();
      far_away.setOrigin(new Ammo.btVector3(-200, -200, -200));

      for (var i = 0, len = boxes.length; i < len; ++i)
        createRigidBody(i);
      for (var i = 0, len = spheres.length; i < len; ++i)
        createRigidBodySphere(spheres[i], i + SPHERES_OFFSET);

      const segbuffer = [];
      function getSegBuffer(i) {
        while(segbuffer.length <= i) {
          segbuffer.push({world_tip: new glMatrix.ARRAY_TYPE(3), sp1: null,
                          world_base: new glMatrix.ARRAY_TYPE(3), sp2: null,
                          sp1_square: Number.MAX_VALUE,
                          sp2_square: Number.MAX_VALUE});
        }
        return segbuffer[i];
      }

      function getSphereFromPool() {
        for(let i = SPOOL_OFFSET; i < spheres.length; i++) {
          if (spheres[i].frameid == frameid)
            continue;
          return spheres[i];
        }
        const sphere = addNewSphere(spheres);
        createRigidBodySphere(sphere, SPHERES_OFFSET + spheres.length - 1);
        return sphere;
      }

      // Convert scanned point values |p| to 3D |v|.
      function convertTo3D(v, x, y, d) {
        const depth = (depthseg.depth_scale * d + 0.007) * viewscale;
        v[0] = depth * (x - depthseg.depth_offset[0]) * depthseg.depth_focal_inv[0];
        v[1] = -depth * (y - depthseg.depth_offset[1]) * depthseg.depth_focal_inv[1];          
        v[2] = -depth;
      };

      function initSegBuffer(seg, buffer) {
        // TODO: fix horizontal orientation
        // Convert segment endpoints to 3D world coordinates.
        const p1 = seg;
        const p2 = depthseg.getSegmentEnd(seg);         

        convertTo3D(tip, p1.x, p1.y, p1.depth); 
        vec3.transformMat4(buffer.world_tip, tip, depth_to_world_transform);
        convertTo3D(base, p2.x, p2.y, p2.depth); 
        vec3.transformMat4(buffer.world_base, base, depth_to_world_transform);

        buffer.sp1 = null;
        buffer.sp2 = null;
        buffer.sp1_square = Number.MAX_VALUE;
        buffer.sp2_square = Number.MAX_VALUE;
        buffer.endpoint_base = !p2.hasOwnProperty("joint");
        buffer.endpoint_tip = !p1.hasOwnProperty("joint");                   
      };

      const MATCH_SPHERE_LIMIT = 0.0004 * viewscale * viewscale; // 2cm
      function getMatchingPreviousFrameSphere(world_center) {
        let nearest = Number.MAX_VALUE;
        let nearest_s = null;
        for (let i = SPOOL_OFFSET, len = spheres.length; i < len; ++i) {
          const s = spheres[i];
          // If it wasn't used in previous frame or already allocated to
          // other point, move to next.
          if (s.frameid != previous_frameid || s.segment || s.contact == false)
            continue;
          const squared_distance = vec3.squaredDistance(s.translate, world_center);
          if (squared_distance < nearest) {
            nearest = squared_distance;
            nearest_s = s;
          }
        }
        if (nearest < MATCH_SPHERE_LIMIT)
          return nearest_s;
        return null;
      }

      // |force| is true for previous frame contact spheres - spheres that were
      // holding the box. We map them to the nearest, so that the picked object
      // wouldn't jump around.
      // Except the potential contact points, the rest of depth segments
      // endpoints are not mapped to previous frame's spheres, but always to
      // a sphere not used in previous frame - cleaned history sphere from the
      // pool is assigned for the depth point. 
      function assignContactSphereToSegmentEndPoint(buffer, spkey, segment, force) {
        const sp = buffer[spkey];
        if (sp == null)
          return;
        const c = (sp == buffer.sp1) ? buffer.world_tip : buffer.world_base;
        sp.segment = segment;
        sp.visible = DEBUG_DRAW_BONES;
        // reposition the physics body
        vec3.copy(sp.translate, c);
        const body = sp.physics_body;
        transform.setIdentity();
        btvec.setValue(c[0], c[1], c[2]);
        transform.setOrigin(btvec);
        body.setWorldTransform(transform);
        body.getMotionState().setWorldTransform(transform);
        // if (sp.frameid == 0 || !contact) {
          body.setLinearVelocity(bt_zero_vec3);
          body.setAngularVelocity(bt_zero_vec3);
          body.forceActivationState(ACTIVE_TAG);
          body.setCollisionFlags(CF_STATIC_OBJECT);
          body.updateInertiaTensor();
        // }
        // if contact is not forced, make it so that it happens only when fingers
        // are well distinguished.
        sp.contact = force || (((segment.far_left.distance2D | 0) +
                                (segment.far_right.distance2D | 0) > 4) &&
                               (segment.count_left + segment.count_right > 8));
        sp.segment_id = segment.index; // debugging purpose only.
        sp.frameid = frameid;
        sp.buffer = buffer;
      }

      function dropObjectsHeldBySphere(sp, index) {
        if (sp.constraints.length > 0)
          contact_spheres.delete(index);
        for (let j = 0; j < sp.constraints.length; j++) {
          const constraint = sp.constraints[j];
          // remove constraints holding the world object.
          const wbox = boxes[constraint.world_item];
          // TODO: remove constraints from other item.
          const finger0 = wbox.constraints[0].finger_item;
          const finger1 = wbox.constraints[1].finger_item;
          
          if (finger0 != index) {
            const s0cons = spheres[finger0].constraints;
            s0cons.splice(s0cons.indexOf(wbox.constraints[0]), 1);
            if (s0cons.length == 0)
              contact_spheres.delete(finger0);           
          } else if (finger1 != index) {
            const s0cons = spheres[finger1].constraints;
            s0cons.splice(s0cons.indexOf(wbox.constraints[1]), 1);           
            if (s0cons.length == 0)
              contact_spheres.delete(finger1);           
          }

          if(wbox.constraints.indexOf(constraint) == -1)
            console.error("wboxcindex == -1");

          wbox.physics_body.getCollisionShape().calculateLocalInertia(wbox.mass, bt_inertia);   
          wbox.physics_body.setMassProps(wbox.mass, bt_inertia);
          wbox.holding_vector_recent = [];
           
          wbox.constraints.length = 0;

        }
        sp.constraints.length = 0;
      }

      function filterOutNoise(v, list) {
        // Filter position noise.
        const p = list.length > 6 ? list.shift() : new glMatrix.ARRAY_TYPE(3);
        vec3.copy(p, v);
        list.push(p);

        if (list.length < 5)
          return;

        vec3.copy(temp, v);
        for (let i = 0; i < list.length - 1; i++)
          vec3.add(temp, temp, list[i]);
        vec3.normalize(temp1, temp);
        
        let maxdiffindex = 0;
        let maxdiff = vec3.squaredDistance(temp1, list[0]);
        for (let i = 1; i < list.length; i++) {
          const diff = vec3.squaredDistance(temp1, list[i]);
          if (diff > maxdiff) {
            maxdiffindex = i;
            maxdiff = diff;
          }
        }
        // remove max diff from computation
        vec3.subtract(temp, temp, list[maxdiffindex]);
        vec3.normalize(v, temp);
      }

      function assignSphereToPoint(sp, x, y, d) {
        const body = sp.physics_body;
        convertTo3D(temp, x, y, d); 
        const c = sp.translate;
        vec3.transformMat4(c, temp, depth_to_world_transform);
        
        sp.visible = DEBUG_DRAW_BONES;
        // reposition the physics body
        transform.setIdentity();
        btvec.setValue(c[0], c[1], c[2]);
        transform.setOrigin(btvec);
        body.setWorldTransform(transform);
        body.getMotionState().setWorldTransform(transform);
        // if (sp.frameid == 0 || !contact) {
          body.setLinearVelocity(bt_zero_vec3);
          body.setAngularVelocity(bt_zero_vec3);
          body.forceActivationState(ACTIVE_TAG);
          body.setCollisionFlags(CF_STATIC_OBJECT);
          body.updateInertiaTensor();
        // }
        sp.frameid = frameid;
        sp.contact = false;
      }

      function updateNet() {
        for (let i = netspheres.length; i < depthseg.out.net.length; i++) {
          const sp = addNewSphere(netspheres);
          createRigidBodySphere(sp, i + NETSPHERES_OFFSET);
        }
        const width = out.netw;
        const height = out.neth;
        const d = depthseg.getDepthNonSkeleton;
        for (let j = 1; j < height - 1; j++) {
          for (let i = 1 + j * width, end = i + width - 2; i < end; i++) {
            const n = out.net[i];
            const sp = netspheres[i];            
            if (n == -1) {
              // hide visible and physics.
              sp.visible = false;
              const body = sp.physics_body;
              body.setLinearVelocity(bt_zero_vec3);
              body.setAngularVelocity(bt_zero_vec3);
              body.setCollisionFlags(CF_NO_CONTACT_RESPONSE | CF_STATIC_OBJECT);
              body.setActivationState(DISABLE_SIMULATION);
              continue;
            }
            const x = n >> 16, y = n & 0xFFFF;
            assignSphereToPoint(sp, x, y, d(x, y));
          }
        }        
      }        

      updateMatrices = function() {
        // TODO: update when changed only
        camera3 = camera3 || camera.object3D.children[0];
        if (!camera3.isPerspectiveCamera)
          throw "Perspective camera API access error";

        // TODO: remove multiplying by projmatrix.
        const projMatrix = camera3.projectionMatrix.elements;
        const viewMatrix = camera3.matrixWorldInverse.elements;
        mat4.multiply(viewProjMatrix, projMatrix, viewMatrix);
        mat4.invert(inverseViewProjMatrix, viewProjMatrix);
        
        mat4.multiply(depth_mvp, camera3.projectionMatrix.elements, depthMesh.modelViewMatrix.elements);
        mat4.multiply(depth_to_world_transform, inverseViewProjMatrix, depth_mvp);
      }

      updateFingerSegments = function() {
        updateMatrices();
        previous_frameid = frameid;
        frameid = ((frameid + 1) & 0xFFFFFFFF) || 1;

        // For all the segment endpoints calculate 3D values. We will use those
        // in several traversals below.
        const segment_data = depthseg.out.segment_data;
        let keys = Object.keys(depthseg.out.segment_data);
        for (let k = 0; k < keys.length; k++) {
          const segment = segment_data[keys[k]];
          const buffer = getSegBuffer(k);
          initSegBuffer(segment, buffer);
        }

        // Identify endpoints (remove the points where two segments touch).
        // We do this so there are less points that could cause tracking/mapping
        // problems.
        let endpoints = 0;
        for (let k = 0; k < keys.length; k++) {
          const buffer = getSegBuffer(k);
          endpoints += ((buffer.endpoint_base ? 1 : 0) +
                        (buffer.endpoint_tip ? 1 : 0));
        }

        // Start from previous frame contact points and get the closest points
        // the latest segments to the previous frame contact points.
        let to_assign = Math.min(contact_spheres.size, endpoints);
        while (to_assign > 0) {
          for (i of contact_spheres) {
            const s = spheres[i];
            if (s.segment != null)
              continue;
            // Get the closest current segment endpoint.
            let nearest = Number.MAX_VALUE;
            let nearest_k = -1;
            let nearest_key = "sp1";
            for (let k = 0; k < keys.length; k++) {
              const buffer = getSegBuffer(k);
              let squared_distance = buffer.endpoint_tip ?
                                     vec3.squaredDistance(s.translate, buffer.world_tip) :
                                     Number.MAX_VALUE;
              if (squared_distance < nearest && squared_distance < buffer.sp1_square) {
                nearest = squared_distance;
                nearest_k = k;
                nearest_key = "sp1";
              }
              squared_distance = buffer.endpoint_base ?
                                 vec3.squaredDistance(s.translate, buffer.world_base) :
                                 Number.MAX_VALUE;
              if (squared_distance < nearest && squared_distance < buffer.sp2_square) {
                nearest = squared_distance;
                nearest_k = k;
                nearest_key = "sp2";
              }
            }
            if (nearest_k == -1)
              continue; // This one doesn't get assigned.
            const buffer = getSegBuffer(nearest_k);
            if (buffer[nearest_key] != null) {
              // There is another sphere claiming it is the closest to the
              // segment endpoint. Invalidate it and do that sphere again.
              to_assign++;
              buffer[nearest_key].segment = null;
              buffer[nearest_key + "_square"] = Number.MAX_VALUE; 
            }
            buffer[nearest_key] = s;
            buffer[nearest_key + "_square"] = nearest; 
            to_assign--;
            s.segment = segment_data[keys[nearest_k]];
          }
        }


        const TEN_CM_SQUARE = 0.01 * viewscale * viewscale;
        // The final step in assigning previous joints - based on
        // buffer.spX.s(phere), 
        function bothHoldsValidAssignment(key, buffer) {
          // If both ends of one segment got assigned as contact points then
          // we have an erroneous situation: contact points should be on
          // different fingers, and previous frame fingertip is probably not
          // visible in this frame so it got reassigned to the closest but
          // wrong point. drop the box.
          if (buffer.sp2 && buffer.sp1)
            return false;
          return buffer[key + "_square"] < TEN_CM_SQUARE;
        }

        for (let k = 0; k < keys.length; k++) {
          const buffer = getSegBuffer(k);
          // We need another sub-step here: check the distances and accept
          // those that are the closest but not the ones that suddenly change
          // the orientation. The idea is to avoid sudden jumps when finger is
          // not visible. For now, drop the object as code bellow will not
          // assign the sphere.
          if (buffer.endpoint_tip && buffer.sp1 &&
              bothHoldsValidAssignment("sp1", buffer)) {
            assignContactSphereToSegmentEndPoint(buffer, "sp1", buffer.sp1.segment, true);
          }
          if (buffer.endpoint_base && buffer.sp2 &&
              bothHoldsValidAssignment("sp2", buffer)) {
            assignContactSphereToSegmentEndPoint(buffer, "sp2", buffer.sp2.segment, true);
          }
        }
        
        // Among other points, get the mapping to previous when they are nearby.
        for (let k = 0; k < keys.length; k++) {
          const segment = segment_data[keys[k]];
          const buffer = getSegBuffer(k);
          if (buffer.endpoint_tip && !buffer.sp1) {
            buffer.sp1 = getMatchingPreviousFrameSphere(buffer.world_tip);
            assignContactSphereToSegmentEndPoint(buffer, "sp1", segment);
          }
          if (buffer.endpoint_base && !buffer.sp2) {
            buffer.sp2 = getMatchingPreviousFrameSphere(buffer.world_base);
            assignContactSphereToSegmentEndPoint(buffer, "sp2", segment);
          }
        }

        for (let k = 0; k < keys.length; k++) {
          const segment = segment_data[keys[k]];
          const buffer = getSegBuffer(k);
          if (buffer.endpoint_tip && !buffer.sp1) {
            // Get from the pool.
            buffer.sp1 = getSphereFromPool();
            assignContactSphereToSegmentEndPoint(buffer, "sp1", segment);
          }
          if (buffer.endpoint_base && !buffer.sp2) {
            buffer.sp2 = getSphereFromPool();
            assignContactSphereToSegmentEndPoint(buffer, "sp2", segment);
          }
        }

        // If 2 fingers holding the object are not holding it anymore, drop the
        // object.
        for (let i = SPOOL_OFFSET, len = spheres.length; i < len; ++i) {
          const sp = spheres[i];
          const body = sp.physics_body;

          if (sp.frameid == previous_frameid) {
            body.setLinearVelocity(bt_zero_vec3);
            body.setAngularVelocity(bt_zero_vec3);
            // getBroadphaseProxy().masks and groups are not compiled in,
            // DISABLE_SIMULATION is not honored so the way to avoid interaction
            // of pool items is to add CF_NO_CONTACT_RESPONSE flag.
            // As this means that the collision is still computed, we move the
            // objects far away to get them processed out during broad phase.
            body.setCollisionFlags(CF_NO_CONTACT_RESPONSE | CF_STATIC_OBJECT);
            body.setActivationState(DISABLE_SIMULATION);
            body.updateInertiaTensor();
            // body.setWorldTransform(far_away);
            // body.getMotionState().setWorldTransform(far_away);
            // remove all the constraints this body has in the world.
            dropObjectsHeldBySphere(sp, i);
          }
          sp.segment = null;
          if (sp.frameid != frameid) {
            sp.frameid = 0;
            sp.visible = false; //sp.physics_body.isActive(); // false;
            sp.buffer = null;
          }
        }

        // Non contact areas get spheres assigned too.
        for (let k = 0; k < keys.length; k++) {
          const segment = segment_data[keys[k]];
          const interpolated_count = depthseg.getSegmentInterpolatedCount(segment);
          for (let i = 0; i < interpolated_count; i++) {
            depthseg.getInterpolatedPoint(temp, segment, i);
            const sp = getSphereFromPool();
            assignSphereToPoint(sp, temp[0], temp[1], temp[2]);
          }
          if (segment.hasOwnProperty("joint")) {
            const sp = getSphereFromPool();
            assignSphereToPoint(sp, segment.x, segment.y, segment.depth);            
          }
        }
          
        // World objects that are hold are getting the rotation from position
        // of fingers holding them.
        for (let i = 0; i < boxes.length; i++) {
          if (boxes[i].constraints.length == 1)
            console.error("shouldnt be 1");
          if (boxes[i].constraints.length > 0) {
            const wb = boxes[i];
            const sp0 = spheres[wb.constraints[0].finger_item];
            const sp1 = spheres[wb.constraints[1].finger_item];
            vec3.subtract(subtract, sp1.translate, sp0.translate);
            
            // If length between fingers is > threshold * initial holding length,
            // drop it.
            const hold_length = vec3.length(subtract);
            if (hold_length > 1.5 * wb.holding_length) {
              // drop the box.
              dropObjectsHeldBySphere(sp0, wb.constraints[0].finger_item);
              continue;
            }

            //  normalize subtract:
            vec3.scale(subtract, subtract, 1 / hold_length);

            // average holding vector to filter out spikes.
            wb.holding_vector_recent = wb.holding_vector_recent || [];
            filterOutNoise(subtract, wb.holding_vector_recent);

            quat.rotationTo(quaternion, wb.holding_vector, subtract);
            quat.multiply(quaternion, quaternion, wb.holding_quat);

            const body = wb.physics_body;
            transform.setIdentity();
            vec3.lerp(subtract, sp0.translate, sp1.translate, 0.5);

            vec3.add(temp, subtract, wb.center_offset);
            btvec.setValue(temp[0], temp[1], temp[2]);
            transform.setOrigin(btvec);
            btquaternion.setValue(quaternion[0], quaternion[1], quaternion[2], quaternion[3]);
            transform.setRotation(btquaternion);

            body.setWorldTransform(transform);
            body.getMotionState().setWorldTransform(transform);
            // body.setLinearVelocity(bt_zero_vec3);
            // body.setAngularVelocity(bt_zero_vec3);
          }
        }
        updateNet();
      }   
    };
    
    function isAngleObtuse(a, b, c) {
      vec3.subtract(temp, a, b);
      vec3.subtract(temp1, c, b);
      return (vec3.dot(temp, temp1) < 0);
    }

    // Can 2 manifolds hold the object? Both manifolds are on the same
    // object, but different finger balls.
    function canManifoldsHoldTheObject(con1, m2, ob, joint, finger) {
      const m1 = con1.manifold;
      const p1 = m1.getContactPoint(0);
      const p2 = m2.getContactPoint(0);

      // First, let's not allow picking objects from the lower side - to
      // prevent this happening when carrying objects.
      // It is box, so on.scale[0] is sufficient - otherwise, use the minimum.
      const ymin = ob.pos[1] - ob.scale[0] * 0.5;
      if (p1.get_m_positionWorldOnA().y() < ymin ||
          p2.get_m_positionWorldOnA().y() < ymin) {
        return false;
      }
      const pA1 = p1.get_m_localPointA();
      const pB1 = p1.get_m_localPointB();
      const pA2 = p2.get_m_localPointA();
      const pB2 = p2.get_m_localPointB();

      // As these are the boxes, holding if pBs are in the same.
      // object to hold is a box, so simplify this so that we hold it on
      // opposite sides of the box.
      const xdiff = Math.abs(pA1.x() - pA2.x());
      const ydiff = Math.abs(pA1.y() - pA2.y());
      const zdiff = Math.abs(pA1.z() - pA2.z());
      if (!(xdiff > 0.9 * ob.scale[0] || ydiff > 0.9 * ob.scale[1] ||
          zdiff > 0.9 * ob.scale[2]))
        return false;
      // Some more math: the direction of the finger; towards or from within
      // the box determines if fingers can hold the object.
      const finger1 = spheres[con1.finger_item];
      const joint1 = finger1.buffer.sp1 == finger1 ? finger1.buffer.world_base
                                                   : finger1.buffer.world_tip;

      // All together, we check 4 angles: joint - fingertip(contact) - center
      // of object for both fingers and joint - fingertip(contact) - center of
      // the grip between two points.
      // If all angles are obtuse (> 90) then it can hold the box.
      if (!isAngleObtuse(ob.pos, finger1.translate, joint1))
        return false;

      if (!isAngleObtuse(ob.pos, finger.translate, joint))
        return false;

      ob.center_offset = ob.center_offset || new glMatrix.ARRAY_TYPE(3);
      vec3.lerp(ob.center_offset, finger.translate, finger1.translate, 0.5);

      if (!isAngleObtuse(ob.center_offset, finger1.translate, joint1))
        return false;

      if (!isAngleObtuse(ob.center_offset, finger.translate, joint))
        return false;

      return true;
    }

    function processManifold(i0, i1, manifold) {
      if (!manifold)
          console.error("undefined manifold");
      i1 = i1 - SPHERES_OFFSET;
      const ob = i0 < SPHERES_OFFSET ? boxes[i0] : spheres[i0 - SPHERES_OFFSET];
      if (ob.constraints.length == 2 && ob.constraints[0].manifold == null)
        return; // already two fingers holding the object, ignore other.
      const finger = spheres[i1];
      if (!finger.contact)
        return;
      const joint = finger.buffer.sp1 == finger ? finger.buffer.world_base
                                                : finger.buffer.world_tip;
      for (let i = 0; i < ob.constraints.length; i++) {
        const con1 = ob.constraints[i];
        if (canManifoldsHoldTheObject(con1, manifold, ob, joint, finger)) {
          // We found the pair, so create real joints and clear the rest.
          // Create constraint from the manifold.                     
          const body = ob.physics_body;
                        
          const finger1 = spheres[con1.finger_item];
          const pt = con1.manifold.getContactPoint(0);
          finger1.constraints.push(con1);
          con1.manifold = null;

          contact_spheres.add(con1.finger_item);

          // The second finger:
          const pt2 = manifold.getContactPoint(0);
          const con2 = {world_item: i0, finger_item: i1, manifold: null};
          ob.constraints = [con1, con2]; // remove all other
          finger.constraints.push(con2);
      
          contact_spheres.add(i1);

          ob.holding_vector = ob.holding_vector || new glMatrix.ARRAY_TYPE(3);
          vec3.subtract(ob.holding_vector, finger.translate, finger1.translate);
          ob.holding_length = vec3.length(ob.holding_vector);
          vec3.scale(ob.holding_vector, ob.holding_vector, 1 / ob.holding_length);
          ob.holding_quat = quat.clone(ob.quat);

          vec3.lerp(ob.center_offset, finger.translate, finger1.translate, 0.5);
          vec3.subtract(ob.center_offset, ob.pos, ob.center_offset);

          body.getCollisionShape().calculateLocalInertia(0, bt_inertia);   
          body.setMassProps(0, bt_inertia);
          body.setLinearVelocity(bt_zero_vec3);
          body.setAngularVelocity(bt_zero_vec3);
          // body.setCollisionFlags(body.getCollisionFlags() | (CF_KINEMATIC_OBJECT | ~CF_STATIC_OBJECT));
          body.updateInertiaTensor();
          return;
        }
      }

      // Since it is not possible to hold an object, cache the manifold.
      const con = {world_item: i0, finger_item: i1, manifold: manifold};
      ob.constraints.push(con);
    }

    function createRigidBody(index) {
      const box = boxes[index];
      const scalestr = box.attributes.getNamedItem("scale").value.slice(0);
      const posstr = box.attributes.getNamedItem("position").value.slice(0);
      const mass = JSON.parse(box.attributes.getNamedItem("mass").value);
      const scale = JSON.parse("[" + scalestr.replace(/ /g, ',') + "]");
      box.scale = scale; // it is used in other demo, so keep it behaving the same until refactoring common code.
      const position = JSON.parse("[" + posstr.replace(/ /g, ',') + "]");
      let shape = new Ammo.btBoxShape(new Ammo.btVector3(scale[0] * 0.5, scale[1] * 0.5, scale[2] * 0.5));
      transform = transform || new Ammo.btTransform();
      transform.setIdentity();
      transform.setOrigin(new Ammo.btVector3(position[0], position[1], position[2]));
      let motionState = new Ammo.btDefaultMotionState(transform);

      shape.calculateLocalInertia(mass, bt_inertia);

      let info = new Ammo.btRigidBodyConstructionInfo(mass, motionState, shape, bt_inertia);
      let body = new Ammo.btRigidBody(info);
      // if (box.hasOwnProperty("frameid"))
      //   body.setCollisionFlags(body.getCollisionFlags() | CF_KINEMATIC_OBJECT);
      box.physics_body = body;
      body.setUserPointer(box);
      body.setUserIndex(index);
      box.constraints = [];
      box.holding_vector = null;
      if (mass > 0) {
        body.setActivationState(DISABLE_DEACTIVATION);
      }
      physics.addRigidBody(body);
    }

    // Internal algorithm assumes box having translate and quat arrays.
    // This makes it.
    function updateBoxesData() {
      for (let i = 1; i < boxes.length; i++) {
        const box = boxes[i];
        box.pos = box.pos || new glMatrix.ARRAY_TYPE(3);
        box.quat = box.quat || new glMatrix.ARRAY_TYPE(4);
        let state = box.physics_body.getMotionState();
        state.getWorldTransform(transform);
        const t = transform.getOrigin();
        let q = transform.getRotation();
        const bt = box.pos;
        const bq = box.quat;
        bt[0] = t.x();
        bt[1] = t.y();
        bt[2] = t.z();
        bq[0] = q.x();
        bq[1] = q.y();
        bq[2] = q.z();
        bq[3] = q.w();
      }
      return true;
    }

    function addConnectionsForContacts() {
      const disp = physics.getDispatcher();
      let data_updated_from_physics_world = false;
      for (let i = 0, num = disp.getNumManifolds(); i < num; i++) {
        const manifold = disp.getManifoldByIndexInternal(i);
        const num_contacts = manifold.getNumContacts();
        if (!num_contacts)
          continue;
        const i0 = manifold.getBody0().getUserIndex();
        const i1 = manifold.getBody1().getUserIndex();
        if(i0 > i1)
          throw "first one should be less than the second";
        if (i0 >= SPHERES_OFFSET)
          continue; // let's pick only boxes.
        if (i1 < SPHERES_OFFSET + SPOOL_OFFSET)
          continue;
        if (i1 >= NETSPHERES_OFFSET)
          continue;
        if (!manifold.getBody1().isActive())
          continue;
        data_updated_from_physics_world =
            data_updated_from_physics_world || updateBoxesData();
        processManifold(i0, i1, manifold);
      }
      // reset back intermediate data.
      for (let i = 1; i < boxes.length; i++) {
        const cons = boxes[i].constraints;
        if (cons.length != 0 && // don't reset if empty already
            (cons.length != 2 || cons[0].manifold != null)) {
          cons.length = 0;         
        }
      }
    }

    function btToScene(s) {
      let state = s.physics_body.getMotionState();
      if (!state)
        return;
      state.getWorldTransform(transform);
      let t = transform.getOrigin();
      let q = transform.getRotation();
      s.object3D.position.set(t.x(), t.y(), t.z());
      s.object3D.quaternion.set(q.x(), q.y(), q.z(), q.w());
    }

    function updatePhysics(time_delta) {
      if ((boxes[1].constraints.length & 1) != 0 ||
          (boxes[2].constraints.length & 1) != 0 ||
          (boxes[3].constraints.length & 1) != 0)
        console.error("expected even number of constraints");
      physics.stepSimulation(time_delta, 10);
      addConnectionsForContacts();

      for (let i = 1; i < boxes.length; i++)
        btToScene(boxes[i]);
      for (let i = 0; i < SPOOL_OFFSET; i++)
        btToScene(spheres[i]);
    }

    const handsView = new THREE.Matrix4();
    // TODO: check the scale
    handsView.lookAt(new THREE.Vector3(0, 0, -5),   // eye
                     new THREE.Vector3(0, 0, 0),   // target
                     new THREE.Vector3(0, 1, 0));  // up

    const hands = {
      uniforms: THREE.UniformsUtils.merge( [
        THREE.UniformsLib[ "fog" ],
        THREE.UniformsLib[ "lights" ],
        {
          "u_depth_texture": {value: null},
          "u_depth_scale": { value: 1.0 },
          "u_depth_offset": { value: [0.0, 0.0] },
          "u_depth_focal_length_inv" : { value: [0.0, 0.0] },
          "u_depth_texture_size" : { value: [0.0, 0.0] },
          "diffuse": { value: new THREE.Color( 0xeeeeee ) },
          "specular": { value: new THREE.Color( 0x111111 ) },
          "shininess": { value: 30 },
          "opacity": { value: 1 },
          "modelViewMatrix1": {value: handsView},
        }

      ] ),

      fragmentShader:`#define PHONG
      uniform vec3 diffuse;
      uniform vec3 emissive;
      uniform vec3 specular;
      uniform float shininess;
      uniform float opacity;

      #include <common>
      #include <packing>
      #include <dithering_pars_fragment>
      #include <color_pars_fragment>
      #include <uv_pars_fragment>
      #include <uv2_pars_fragment>
      #include <map_pars_fragment>
      #include <alphamap_pars_fragment>
      #include <aomap_pars_fragment>
      #include <lightmap_pars_fragment>
      #include <emissivemap_pars_fragment>
      #include <envmap_pars_fragment>
      #include <gradientmap_pars_fragment>
      #include <fog_pars_fragment>
      #include <bsdfs>
      #include <lights_pars>
      #include <lights_phong_pars_fragment>
      #include <shadowmap_pars_fragment>
      #include <bumpmap_pars_fragment>
      #include <normalmap_pars_fragment>
      #include <specularmap_pars_fragment>
      #include <logdepthbuf_pars_fragment>
      #include <clipping_planes_pars_fragment>

      varying vec4 v_depth_color;
      varying float v_valid;

      void main() {

        #include <clipping_planes_fragment>

        if (v_valid != 0.0)
          discard;
        vec4 diffuseColor = vec4( diffuse, opacity );
        // diffuseColor = v_depth_color;
        ReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );
        vec3 totalEmissiveRadiance = emissive;

        #include <logdepthbuf_fragment>
        #include <map_fragment>
        #include <color_fragment>
        #include <alphamap_fragment>
        #include <alphatest_fragment>
        #include <specularmap_fragment>
        #include <normal_fragment>
        #include <emissivemap_fragment>

        // accumulation
        #include <lights_phong_fragment>
        #include <lights_template>

        // modulation
        #include <aomap_fragment>

        vec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;

        #include <envmap_fragment>

        gl_FragColor = vec4( outgoingLight, diffuseColor.a );

        #include <tonemapping_fragment>
        #include <encodings_fragment>
        #include <fog_fragment>
        #include <premultiplied_alpha_fragment>
        #include <dithering_fragment>

      }`,

      vertexShader: `#define PHONG
      varying vec3 vViewPosition;
      varying vec4 v_depth_color;

      #ifndef FLAT_SHADED

        varying vec3 vNormal;

      #endif

      #include <common>
      #include <uv_pars_vertex>
      #include <uv2_pars_vertex>
      #include <displacementmap_pars_vertex>
      #include <envmap_pars_vertex>
      #include <color_pars_vertex>
      #include <fog_pars_vertex>
      #include <morphtarget_pars_vertex>
      #include <skinning_pars_vertex>
      #include <shadowmap_pars_vertex>
      #include <logdepthbuf_pars_vertex>
      #include <clipping_planes_pars_vertex>

      varying float v_valid;
      uniform float u_depth_scale;
      uniform vec2 u_depth_offset;
      uniform vec2 u_depth_focal_length_inv;
      uniform sampler2D u_depth_texture;
      uniform vec2 u_depth_texture_size;
      uniform mat4 modelViewMatrix1;
      vec3 depth_deproject(vec2 index, float depth) {
        vec2 position2d = (index - u_depth_offset) * u_depth_focal_length_inv;
        return vec3(position2d * depth, -depth);
      }

      void main() {

        #include <uv_vertex>
        #include <uv2_vertex>
        #include <color_vertex>

        #include <beginnormal_vertex>
        #include <morphnormal_vertex>
        #include <skinbase_vertex>
        #include <skinnormal_vertex>
        #include <defaultnormal_vertex>

      #ifndef FLAT_SHADED // Normal computed with derivatives when FLAT_SHADED

        vNormal = normalize( transformedNormal );

      #endif

        #include <begin_vertex> // vec3 transformed = vec3( position )
        // position.xy are in range [-0.5, 0.5]
        float depth = texture2D(u_depth_texture, vec2(position.x, position.y) + 0.5).r;
        v_valid = depth > 0.0001 ? 0.0 : 1.0;
        float depth_scaled = u_depth_scale * depth;
        vec2 index = (vec2(position.x, position.y) + 0.5) * u_depth_texture_size;
        transformed = depth_deproject(index, depth_scaled);
        
        v_depth_color = vec4(depth, depth, depth, 1.0) * 10.0; // TODO: remove as it is only for testing
        // #include <project_vertex>
        vec4 mvPosition = modelViewMatrix * vec4( transformed, 1.0 );
        gl_Position = projectionMatrix * mvPosition;
        #include <logdepthbuf_vertex>
        #include <clipping_planes_vertex>

        vViewPosition = - mvPosition.xyz;

        // #include <worldpos_vertex>
        #if defined( USE_ENVMAP ) || defined( PHONG ) || defined( PHYSICAL ) || defined( LAMBERT ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP )
          vec4 worldPosition = modelMatrix * vec4(transformed, 1.0);
        #endif
        #include <envmap_vertex>
        #include <shadowmap_vertex>
        #include <fog_vertex>
      }`
    };

    const hands_shadow = {
      uniforms: THREE.UniformsUtils.merge([
        THREE.UniformsLib.common,
        THREE.UniformsLib.displacementmap,
        {
          "u_depth_texture": {value: null},
          "u_depth_scale": { value: 1.0 },
          "u_depth_offset": { value: [0.0, 0.0] },
          "u_depth_focal_length_inv" : { value: [0.0, 0.0] },
          "u_depth_texture_size" : { value: [0.0, 0.0] },
          "modelViewMatrix1": {value: handsView},
        }
      ]),

      fragmentShader:`
      #define DEPTH_PACKING 3201
      #if DEPTH_PACKING == 3200
        uniform float opacity;
      #endif
      #include <common>
      #include <packing>
      #include <uv_pars_fragment>
      #include <map_pars_fragment>
      #include <alphamap_pars_fragment>
      #include <logdepthbuf_pars_fragment>
      #include <clipping_planes_pars_fragment>
      varying float v_valid;
      void main() {
        if (v_valid != 0.0)
          discard;
        #include <clipping_planes_fragment>
        vec4 diffuseColor = vec4( 1.0 );
        #if DEPTH_PACKING == 3200
          diffuseColor.a = opacity;
        #endif
        #include <map_fragment>
        #include <alphamap_fragment>
        #include <alphatest_fragment>
        #include <logdepthbuf_fragment>
        #if DEPTH_PACKING == 3200
          gl_FragColor = vec4( vec3( gl_FragCoord.z ), opacity );
        #elif DEPTH_PACKING == 3201
          gl_FragColor = packDepthToRGBA( gl_FragCoord.z );
        #endif
      }
      `,

      vertexShader: `#include <common>
      #include <uv_pars_vertex>
      #include <displacementmap_pars_vertex>
      #include <morphtarget_pars_vertex>
      #include <skinning_pars_vertex>
      #include <logdepthbuf_pars_vertex>
      #include <clipping_planes_pars_vertex>

      varying float v_valid;
      uniform float u_depth_scale;
      uniform vec2 u_depth_offset;
      uniform vec2 u_depth_focal_length_inv;
      uniform sampler2D u_depth_texture;
      uniform vec2 u_depth_texture_size;
      uniform mat4 modelViewMatrix1;
      vec3 depth_deproject(vec2 index, float depth) {
        vec2 position2d = (index - u_depth_offset) * u_depth_focal_length_inv;
        return vec3(position2d * depth, -depth);
      }

      void main() {
        #include <uv_vertex>
        #include <skinbase_vertex>
        #ifdef USE_DISPLACEMENTMAP
          #include <beginnormal_vertex>
          #include <morphnormal_vertex>
          #include <skinnormal_vertex>
        #endif
        #include <begin_vertex>

        // position.xy are in range [-0.5, 0.5]
        float depth = texture2D(u_depth_texture, vec2(position.x, position.y) + 0.5).r;
        v_valid = depth > 0.0001 ? 0.0 : 1.0;
        float depth_scaled = u_depth_scale * depth;
        vec2 index = (vec2(position.x, position.y) + 0.5) * u_depth_texture_size;
        transformed = depth_deproject(index, depth_scaled);

        #include <morphtarget_vertex>
        #include <skinning_vertex>
        #include <displacementmap_vertex>
//        #include <project_vertex>
        vec4 mvPosition = modelViewMatrix * vec4( transformed, 1.0 );
        gl_Position = projectionMatrix * mvPosition;

        #include <logdepthbuf_vertex>
        #include <clipping_planes_vertex>
      }`
    };

    let depthMesh;
    function recreateDepthMesh() {
      let uniformsHands = THREE.UniformsUtils.clone(hands.uniforms);
      
      if (!scene.renderer.context.three_depth_texture) {
        const texture = new THREE.Texture();
        const texProperties = scene.renderer.properties.get(texture);
        texProperties.__webglTexture = scene.renderer.context.depth_texture;
        texProperties.__webglInit = true;
        scene.renderer.context.three_depth_texture = texture;
      }

      // Continue construction when depth video is loaded as then we have video frame size available.
      function depthVideoLoaded() {
        if (camera.object3D.children.length < 1)
          return;
        if (depthMesh)
          camera.object3D.remove(depthMesh);

        function setDepthUniforms(uniforms) {
          uniforms['u_depth_scale'].value = depthseg.depth_scale * viewscale;
          uniforms['u_depth_focal_length_inv'].value = depthseg.depth_focal_inv;
          uniforms['u_depth_offset'].value = depthseg.depth_offset;
          uniforms['u_depth_texture_size'].value = [depthseg.width, depthseg.height];
          uniforms['u_depth_texture'].value = scene.renderer.context.three_depth_texture;
        };
        setDepthUniforms(uniformsHands);
        let material = new THREE.ShaderMaterial({uniforms: uniformsHands,
            vertexShader: hands.vertexShader, fragmentShader: hands.fragmentShader,
            lights: true, fog: false, side: THREE.DoubleSide});

        depthMesh = new THREE.Mesh(new THREE.PlaneBufferGeometry(1, 1, depthseg.width, depthseg.height), material);

        let uniformsHandsShadow = THREE.UniformsUtils.clone(hands_shadow.uniforms);
        setDepthUniforms(uniformsHandsShadow);
        depthMesh.customDepthMaterial = new THREE.ShaderMaterial({
          uniforms: uniformsHandsShadow,
          vertexShader: hands_shadow.vertexShader,
          fragmentShader: hands_shadow.fragmentShader,
          fog: false, side: THREE.DoubleSide, depthPacking: THREE.RGBADepthPacking,
        });
        
 /*       const posstr = camera.attributes.getNamedItem("position").value.slice(0);
        const position = JSON.parse("[" + posstr.replace(/ /g, ',') + "]");
        depthMesh.position.y = position[1];
        depthMesh.position.z = position[2];*/
        // depthMesh.rotation.set(-0.52, 0, 0);
        depthMesh.position.y = 0.15; // about 15 centimeters above the HMD.
        depthMesh.rotation.set(-0.15, 0, 0); // rotate depth camera a bit down.
        depthMesh.scale.x = 1.5; // TODO: calculate.        
        depthMesh.scale.y = 1.5;        
        depthMesh.castShadow = true;
        depthMesh.receiveShadow = true;
        depthMesh.width = depthseg.width;
        camera.object3D.add(depthMesh);
      }
      depthseg.depthVideoLoadedCallback = depthVideoLoaded;
      if (depthseg.depth_focal_inv)
        depthVideoLoaded();
    }

    AFRAME.registerSystem('physics', {
      init: function () {
        scene = document.querySelector('a-scene');
        camera = document.querySelector('a-camera');
        Ammo().then(function(Ammo) {
          // Physics setup
          var collisionConfiguration = new Ammo.btDefaultCollisionConfiguration();
          var dispatcher = new Ammo.btCollisionDispatcher(collisionConfiguration);
          var pairCache = new Ammo.btDbvtBroadphase();
          var solver = new Ammo.btSequentialImpulseConstraintSolver();
          physics = new Ammo.btDiscreteDynamicsWorld(dispatcher, pairCache, solver,collisionConfiguration);
          const gravity = new Ammo.btVector3(0, -9.81 / viewscale, 0);
          physics.setGravity(gravity);
          sceneLoaded();
        });
      },
      tick: function (now, delta) {
        if (physics) {
          if (depthseg.process(scene.renderer.context))
            updateFingerSegments();
          if (!depthMesh || depthMesh.width != depthseg.width)
            recreateDepthMesh();
          updatePhysics(delta);
        }
      }
    });  

    AFRAME.registerComponent('mass', {
      schema: { type: 'number',default: NaN, },
      init: function() {
        this.el.mass = this.data;
      }
    });
  </script>
  <a-scene physics>
    <a-assets>
      <img id="webgl" src="webgl.png">
      <img id="grid" src="grid.png">
      <img id="bone" src="bone.png">
    </a-assets>
    <a-box src="#grid" repeat="20 20" color="#7BC8A4" transparent="true" opacity="0.5" position="0 0 0" scale="30 0.5 30" mass="0" shadow></a-box>
    <a-box src="#webgl" color="#4CC3D9" position="1 0.75 0" scale="1 1 1" mass="5" shadow></a-box>
    <a-box src="#webgl" color="#4CC3D9" position="3 0.75 0" scale="1 1 1" mass="5" shadow></a-box>
    <a-box src="#webgl" color="#FFC65D" position="-1 2.75 0" scale="1 1 1" mass="5" shadow></a-box>
    <a-sky color="#ECECEC"></a-sky>
    <a-entity position="0 5 3" rotation="-45 0 0">
      <a-camera></a-camera>
    </a-entity>
    <a-entity light="type: ambient; color: #BBB"></a-entity>
    <a-entity light="color: #FFF; intensity: 0.6; castShadow: true; shadowBias: -0.0001; shadowCameraTop: 10; shadowCameraRight: 10; shadowCameraBottom: -10; shadowCameraLeft: -10; shadowMapHeight:1024; shadowMapWidth:1024" position="10 10 3"></a-entity>  </a-scene>
  <div class="info">
    Hand physics - depth camera capture demo.
    <div>
      <a href="https://github.com/intel/depth-camera-web-demo">Source code on GitHub</a>
    </div>
    <div id="console" style="color: red; font-size: x-large;"></div>

  </div>
</body>
</html>
